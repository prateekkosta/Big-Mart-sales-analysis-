{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekkosta/Big-Mart-sales-analysis-/blob/main/BigMart_Data_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCKpojetvSiL"
      },
      "source": [
        "**Objective**\n",
        "Predict the sales of each product by understanding product properties and ourlet sales by implementing some Machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2BVotcPu3oN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import mode\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuVwY66VxFDT"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv('/content/drive/MyDrive/Train big mart.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IXB6jp2xFHa"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7Cx6oIFxFKm"
      },
      "outputs": [],
      "source": [
        "# Checking statical features of Dataset\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHAfl3d6xFNC"
      },
      "outputs": [],
      "source": [
        "#Checking for number of Rows and Columns\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "847QeLLoxFP4"
      },
      "outputs": [],
      "source": [
        "#Checking for type of data in each column\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruJkjPC00hoC"
      },
      "source": [
        "As we can see from dataset info that Item_Weight and Outlet_Size has some missing values which we have to impute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUwtW88OxFS-"
      },
      "outputs": [],
      "source": [
        "#Checking for Unique values\n",
        "df.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UzpwII01X1H"
      },
      "source": [
        "As we can see that Dataset has 1559 type of products, 16 type of items, 3 type of outlet size, 3 type of Outlet Location and 4 type of outlet type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuTawhU-xFXJ"
      },
      "outputs": [],
      "source": [
        "# Checking for Null values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWsnbggb8opb"
      },
      "source": [
        "Columns Item_Weight contains 1463 null values and Outlet_Size contains 2410 Null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCwd1OAixFaD"
      },
      "outputs": [],
      "source": [
        "# Now we will look for Object Data type columns i.e. columns which has categorical type of data.\n",
        "\n",
        "object_column= []\n",
        "for i in df:\n",
        "  if df[i].dtype== 'object':\n",
        "    object_column.append(i)\n",
        "object_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjzf8Q_3-zCU"
      },
      "source": [
        "Since Item_Identifier and Outlet_Identifier are just unique ids provided to products and stores, so we can remove them for our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx-H6-mkxFc1"
      },
      "outputs": [],
      "source": [
        "object_column.remove('Outlet_Identifier')\n",
        "object_column.remove('Item_Identifier')\n",
        "object_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzHGJ6f1LKKY"
      },
      "source": [
        "Now checking that which type of data are present in these columns and how many type of data is present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slwcbHIUxFfk"
      },
      "outputs": [],
      "source": [
        "#Checking for data type and type of Data\n",
        "\n",
        "for i in object_column:\n",
        "  print(i)\n",
        "  print(df[i].value_counts())\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESoYgoPzOCdZ"
      },
      "source": [
        "## Missing Value Imputation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR5-1nj0OLQ2"
      },
      "source": [
        "Now I will replace the mean value of different products acccording to their type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T32PhsSSxFie"
      },
      "outputs": [],
      "source": [
        "item_weight_mean= df.groupby('Item_Identifier').agg({'Item_Weight': np.mean})\n",
        "item_weight_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bERGsmabxFlY"
      },
      "outputs": [],
      "source": [
        "# finding boolean values of missing data.\n",
        "\n",
        "missing_item_weight= df['Item_Weight'].isnull()\n",
        "missing_item_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWurck-2Ryii"
      },
      "source": [
        "Now I will look at location where boolean is true and check for product type in that locations and than replace missing values with mean of same products types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNe_DxR-xFoH"
      },
      "outputs": [],
      "source": [
        "for i, item in enumerate(df['Item_Identifier']):\n",
        "  if missing_item_weight[i]:\n",
        "    if item in item_weight_mean:\n",
        "      df['Item_Weight'][i]= item_weight_mean.loc['item']['item_weight']\n",
        "    else:\n",
        "      df['Item_Weight'][i]= np.mean(df['Item_Weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmuVXwQTxFq4"
      },
      "outputs": [],
      "source": [
        "df['Item_Weight'].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iXH6N05Wmr2"
      },
      "source": [
        "Now finding outlet type with their respective mode values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APM3Au_wxFt2"
      },
      "outputs": [],
      "source": [
        "outlet_size_mode= df.pivot_table(values= 'Outlet_Size', columns= 'Outlet_Type', aggfunc=( lambda x: x.mode([0])) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zQkYmeHxFw8"
      },
      "outputs": [],
      "source": [
        "outlet_size_mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMlsb0RfxFzj"
      },
      "outputs": [],
      "source": [
        "missing_outlet= df['Outlet_Size'].isnull()\n",
        "missing_outlet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1ctBwdGxF2g"
      },
      "outputs": [],
      "source": [
        "#Replaccing values in column\n",
        "\n",
        "df.loc[missing_outlet, 'Outlet_Size']= df.loc[missing_outlet, 'Outlet_Type'].apply(lambda x: outlet_size_mode[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr1YOOfCxF5y"
      },
      "outputs": [],
      "source": [
        "df['Outlet_Size'].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0CG0hAlu6CB"
      },
      "source": [
        "**From the describe function we have seen that item visibility has 0 values which makes no practical sense. So we will replace 0 Value with mean of Item_visibility.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN6A1NLbxF8k"
      },
      "outputs": [],
      "source": [
        "(df['Item_Visibility']==0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZSi2vQ2xGBD"
      },
      "outputs": [],
      "source": [
        "df.loc[:,'Item_Visibility'].replace([0], [df['Item_Visibility'].mean()], inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOmE4hMUxGDn"
      },
      "outputs": [],
      "source": [
        "(df['Item_Visibility']==0).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e1V5UjJx4yw"
      },
      "source": [
        "As we can see from the Data that Item_fat_content column has similar type of values with multiple names like Low Fat is also written as LF, low fat and Regular is written as Reg. So we will make it as same type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9BWRbS2xEo0"
      },
      "outputs": [],
      "source": [
        "df['Item_Fat_Content']= df['Item_Fat_Content'].replace({'LF':'Low Fat', 'low fat': 'Low Fat', 'reg':'Regular'})\n",
        "df['Item_Fat_Content'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIDFml-Awrs_"
      },
      "source": [
        "# **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Icux6vZZww0I"
      },
      "source": [
        "Now we will extract first two words from Item Identifiers to make a new column New Item Type which will define weather it is food, drinking or Non Consumable item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OeXXo_v6xEso"
      },
      "outputs": [],
      "source": [
        "df['New_Item_Type']= df['Item_Identifier'].apply(lambda x: x[:2])\n",
        "df['New_Item_Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ4RD6g-xExm"
      },
      "outputs": [],
      "source": [
        "df['New_Item_Type']= df['New_Item_Type'].map(({'FD': 'Food', 'DR': 'Drinking', 'NC': 'Non-Consumable'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gklK7DRsxE1P"
      },
      "outputs": [],
      "source": [
        "df.New_Item_Type.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY-HrIhOzIN1"
      },
      "source": [
        "No we will check the New Items which are Non-Consumable and if they contain fat make it non edible item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oM1ujZc1XTr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_6-6DeLxE4c"
      },
      "outputs": [],
      "source": [
        "df.loc[df['New_Item_Type']== 'Non-Consumable', 'Item_Fat_Content']= 'Non-Edible'\n",
        "df['Item_Fat_Content'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdGHWb_PxE7t"
      },
      "outputs": [],
      "source": [
        "perishable_item= [\"Breads\", \"Breakfast\", \"Dairy\", \"Snack Foods\",\"Fruits and Vegetables\", \"Meat\", \"Seafood\", \"Starchy Foods\"]\n",
        "non_perishable_item= [\"Baking Goods\", \"Canned\", \"Frozen Foods\", \"Hard Drinks\", \"Health and Hygiene\",\"Household\", \"Soft Drinks\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsS_d-6UxE-m"
      },
      "outputs": [],
      "source": [
        "def New_Item_Type(item):\n",
        "  if item in perishable_item:\n",
        "    return 'Perishable'\n",
        "  elif item in non_perishable_item:\n",
        "    return 'Non-Perishable'\n",
        "  else:\n",
        "    return 'Not-Known'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxYDHG93xFB1"
      },
      "outputs": [],
      "source": [
        "df['Shelf_Life']= df['Item_Type'].apply(New_Item_Type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa9RcgfgxFEv"
      },
      "outputs": [],
      "source": [
        "df['Shelf_Life'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2RMn34q7f5j"
      },
      "outputs": [],
      "source": [
        "df['MRP_per_unit_weight']= df['Item_MRP']/ df['Item_Weight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7coF6z9N7f8Y"
      },
      "outputs": [],
      "source": [
        "df['Outlet_years']= 2013 - df['Outlet_Establishment_Year']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VxklibO7f_w"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oraVvsA69FVW"
      },
      "source": [
        "# **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9kqiuTK9Ny2"
      },
      "source": [
        "Visualization of Numerical features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQC9AeH17gC-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (8,6))\n",
        "sns.distplot(df['Item_Weight'],bins= 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL2YIGqc7gGg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (8,6))\n",
        "sns.distplot(df['Item_Visibility'], bins=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Bh4v6M17gKs"
      },
      "outputs": [],
      "source": [
        "df['Item_Visibility']= np.log(df['Item_Visibility'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i092BceH7gO6"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_Visibility'], bins= 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQnaUwAgCyye"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_MRP'], bins= 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIrYL_CK7gSJ"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_Outlet_Sales'], bins= 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIHv6RtQDTFE"
      },
      "source": [
        "Here item outlet sale is Right skewed and we have to make it normally distributed, so applying log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIz-by1p7gVe"
      },
      "outputs": [],
      "source": [
        "df['Item_Outlet_Sales']= np.log(1+ df['Item_Outlet_Sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8Dy0dC67gYw"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_Outlet_Sales'], bins= 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax0GmrSAFvtl"
      },
      "source": [
        "**Visualization of Categorical features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54lytfeS_pns"
      },
      "outputs": [],
      "source": [
        "df['Item_Type']=df['Item_Type'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWzJYFXs7gb7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (8,6))\n",
        "Item_Type_Vis= sns.countplot(x= 'Item_Type', data= df)\n",
        "Item_Type_Vis.set_xticklabels(Item_Type_Vis.get_xticklabels(), rotation= 80)\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym5WvVOK7gln"
      },
      "outputs": [],
      "source": [
        "Outlet_Type_Vis= sns.countplot(x= 'Outlet_Type', data= df)\n",
        "Outlet_Type_Vis.set_xticklabels(Outlet_Type_Vis.get_xticklabels(), rotation= 40)\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTnhAaAC7gpc"
      },
      "outputs": [],
      "source": [
        "Outlet_Size_Vis= sns.countplot(x= 'Outlet_Size', data= df)\n",
        "Outlet_Size_Vis.set_xticklabels(Outlet_Size_Vis.get_xticklabels())\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muS5X2Ou7gsc"
      },
      "outputs": [],
      "source": [
        "Item_Fat_Content_Vis= sns.countplot(x= \"Item_Fat_Content\", data= df)\n",
        "Item_Fat_Content_Vis.set_xticklabels(Item_Fat_Content_Vis.get_xticklabels())\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9J3wsk57gvs"
      },
      "outputs": [],
      "source": [
        "Outlet_Location_type_Vis= sns.countplot(x='Outlet_Location_Type', data= df)\n",
        "Outlet_Location_type_Vis.set_xticklabels(Outlet_Location_type_Vis.get_xticklabels())\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XDXE0BTOYN_"
      },
      "source": [
        "# **Bivariate Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G-tq_J07gyn"
      },
      "outputs": [],
      "source": [
        "#Now We will check Average sales Outlet location Type wise\n",
        "\n",
        "Outlet_location_Sales= sns.barplot(x= 'Outlet_Location_Type', y= np.exp(df['Item_Outlet_Sales']), data= df)\n",
        "Outlet_location_Sales.set_xticklabels(Outlet_location_Sales.get_xticklabels())\n",
        "plt.title('Outlet Location Type Vs Item Outlet Sales', fontsize= 16)\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6NFs-bP7g18"
      },
      "outputs": [],
      "source": [
        "# Checking for Average sales Outlet Type wise\n",
        "\n",
        "Outlet_type_sales= sns.barplot(x= 'Outlet_Type', y= np.exp(df['Item_Outlet_Sales']), data= df)\n",
        "Outlet_type_sales.set_xticklabels(Outlet_type_sales.get_xticklabels(), rotation= 80)\n",
        "plt.title('Outlet Type vs Item Outlet Sales')\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftLsD6IjVK2r"
      },
      "outputs": [],
      "source": [
        "# Checking for Avg sales Outlet size wise.\n",
        "\n",
        "Outlet_Size_sales= sns.barplot(x= 'Outlet_Size', y= np.exp(df['Item_Outlet_Sales']), data= df)\n",
        "Outlet_Size_sales.set_xticklabels(Outlet_Size_sales.get_xticklabels(), rotation= 80)\n",
        "plt.title('Outlet Size vs Item Outlet Sales')\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKAIziClVK5s"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (15,8))\n",
        "Item_type_sales= sns.barplot(x='Item_Type', y= np.exp(df['Item_Outlet_Sales']), data= df)\n",
        "Item_type_sales.set_xticklabels(Item_type_sales.get_xticklabels(), rotation= 80)\n",
        "plt.title('Item Type Vs Item Outlet Sales')\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rexm1WePVK9C"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfi2VUagVLAy"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize= (8,6))\n",
        "sns.heatmap(df.corr(), annot= True)\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXLsfIyivkpF"
      },
      "source": [
        "There is no significant Correlation observed except Item MRP vs Item Outlet Sales because if Item MRP increase sales is also increased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOX-L9nOwHQz"
      },
      "source": [
        "## **Now we will check outlet total sales through Pivot table with diffrent features.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oInQaeenVLEb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.options.display.float_format= '{:.2f}'.format\n",
        "df.pivot_table(values= 'Item_Outlet_Sales', index=['Outlet_Location_Type', 'Outlet_Type', 'Outlet_Size'], aggfunc= np.sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4p0cUvMQVLIK"
      },
      "outputs": [],
      "source": [
        "df.pivot_table(values=  'Item_Outlet_Sales', index=[ 'Item_Fat_Content', 'New_Item_Type', 'Item_Type' ], aggfunc= np.sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JK3HwnpVLLp"
      },
      "outputs": [],
      "source": [
        "df.pivot_table(values= \"Item_Outlet_Sales\", index= ['Outlet_Size', 'Outlet_Identifier'], aggfunc= np.sum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ0G2Qzu3NfT"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfGtQ4ac3NmM"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioyC-zKOVLO_"
      },
      "outputs": [],
      "source": [
        "#Doing label incoding for variables which has internal dependency.\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le= LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v962HMX7VLSo"
      },
      "outputs": [],
      "source": [
        "df['Outlet']= le.fit_transform(df['Outlet_Identifier'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "min_ucw17ZNe"
      },
      "source": [
        "### **One Hot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BcXBM0FVLWU"
      },
      "outputs": [],
      "source": [
        "#One Hot Encoding for variables which has no internal dependency.\n",
        "\n",
        "df= pd.get_dummies(df, columns=['Outlet_Type','Item_Fat_Content','New_Item_Type','Outlet_Size','Outlet_Location_Type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY5FZfs4VLaD"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7kwe_ggVLdZ"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWywr-O4VLiC"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_7XZzuIIyKz"
      },
      "source": [
        "### **Spliting the Data into Train and Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SoC7dooVLlx"
      },
      "outputs": [],
      "source": [
        "train= df.drop(['Item_Outlet_Sales', 'Item_Identifier', 'Item_Type', 'Outlet_Identifier', 'Shelf_Life'], axis= 1)\n",
        "test= df['Item_Outlet_Sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VIcL1ndVLoz"
      },
      "outputs": [],
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THYvNzNbJ3xk"
      },
      "source": [
        "## *Statical Analysis*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuh8aIfeVLr2"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwP1SI1oVLv6"
      },
      "outputs": [],
      "source": [
        "x= train\n",
        "y=test\n",
        "x= sm.add_constant(x)\n",
        "result= sm.OLS(y,x).fit()\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGBpuzjiOK31"
      },
      "source": [
        "# **Observations**\n",
        "\n",
        "\n",
        "1.   P value for F static is < 0.05 so we can say that our model is significant(at least for one independent variable the the regression coef. is not equal to zero, rejecting the Null Hypothesis. In this the Null Hypothesis is 'All the regression coef. are equal to zero.\n",
        "2.   R-Squared value indicate that 72.1 percentage of variance is explained by our model. Adjusted R-square is less than R-square which indicate that model has some insignificant attributes.\n",
        "3.  Checked for P Values, If P-value is < 0.05 we will say that attribut is contributing to model that means rejecting the Null Hypothesis and if P- value is >0.05 it means the atribute is insignificant that means accepting the Null Hypothesis.\n",
        "4.  Looking at P-values we can say that attributes ['Item_Weight','Item_Visibility','MRP_per_unit_weight','Item_Fat_Content_Low Fat', 'Item_Fat_Content_Non-Edible','New_Item_Type_Drinking','New_Item_Type_Food','Item_Fat_Content_Regular', 'New_Item_Type_Non-Consumable','Outlet_Location_Type_Tier 2'] has no cobtribution in dependent variables.\n",
        "5.  We can say that these attributes are not affecting sales.\n",
        "6.  Prob(Omnibus)- One of the assumption of OLS method is that errors are normally distributed and Omnibus test is performed to check normal distribution. Here the null hypothesis is that the errors are normally dirtibuted. Prob(Omnibus) is supposed to be closed to 1 in order to satisfy OLS method but in this case Prob(Omnibus) is close to 0.00 which means OLS method is not satisfied, errors are not normally distributed.\n",
        "7.  Durbin-Watson- The value of this is 2.008 which is close to 2 this means this data has no sutocorelation.\n",
        "8.  Prob(Jarque-Bera)- It is in line with Omnibus test. It is also performed for destribution analysis of regression errors. It is supposed to agree with the Omnibus test and large value of JB Test indicate that errors are not normally distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-SO6ZaEVLzV"
      },
      "outputs": [],
      "source": [
        "train_1= train.drop(['Item_Weight','Item_Visibility','MRP_per_unit_weight','Item_Fat_Content_Low Fat',\n",
        "                     'Item_Fat_Content_Non-Edible','New_Item_Type_Drinking',\n",
        "                     'New_Item_Type_Food','Item_Fat_Content_Regular', 'New_Item_Type_Non-Consumable','Outlet_Location_Type_Tier 2'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFBq9Fx57g5d"
      },
      "outputs": [],
      "source": [
        "x= train_1\n",
        "y= test\n",
        "\n",
        "x= sm.add_constant(x)\n",
        "result= sm.OLS(y,x).fit()\n",
        "print(result.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lktLbXJ5VJV7"
      },
      "source": [
        "## **Observation**\n",
        "\n",
        "\n",
        "1.   F- Static is increased by a significant amount, so model is significant.\n",
        "2.   R-Squares is decreased it means that dropped attributes are insignificant for model.\n",
        "3.  The p values of all the attributes are <0.05 that means all the selected attributes are significant to dependent variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqxM6PbJWf25"
      },
      "source": [
        "## **Splitting Data into Train and Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGiBleXWxFIm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPed6VgAxFLl"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test= train_test_split(train_1, test, test_size= .25, shuffle= True, random_state= 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uifPV_TexFOa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URy1aKF-axzW"
      },
      "source": [
        "## **Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMpVM6QpxFRi"
      },
      "outputs": [],
      "source": [
        "def model_details(model, algo):\n",
        "  y_pred= model.predict(x_test)\n",
        "  rmse= np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "  mae= mean_absolute_error(y_test, y_pred)\n",
        "  accu= round(model.score(x_test, y_test)*100,2)\n",
        "  cvs= cross_val_score(model, x_test, y_test, cv= 5)\n",
        "  mean= round(cvs.mean()*100,2)\n",
        "  std= round(cvs.std()*2,2)\n",
        "  print(\"Model Report\")\n",
        "  print('Acuuracy of {}: {}%'.format(algo, accu),)\n",
        "  print('RMSE value: ', round(rmse,2))\n",
        "  print('Cross Validation Score : Mean - {}| Std - {}'.format(mean, std))\n",
        "  print('MAE value: ', round(mae, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qg18AQLXia0"
      },
      "source": [
        "### **Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF55CoX7Xeoz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYCk8c8PXetB"
      },
      "outputs": [],
      "source": [
        "base_model= np.exp(test.mean())\n",
        "base_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwtPuj_9XexW"
      },
      "outputs": [],
      "source": [
        "base_model= [base_model]* len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7glVgtrXe1N"
      },
      "outputs": [],
      "source": [
        "base_rmse=  np.sqrt(mean_squared_error(np.exp(test), base_model))\n",
        "base_mae= mean_absolute_error(np.exp(test), base_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHt799K4Xe5R"
      },
      "outputs": [],
      "source": [
        "print(base_rmse)\n",
        "print(base_mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wA9ifcfXe9K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear Regression**"
      ],
      "metadata": {
        "id": "5pLMtt5HZ_Y9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py9YQhmiXfAk"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "LR= LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXY55UykXfEN"
      },
      "outputs": [],
      "source": [
        "LR.fit(x_train, y_train)\n",
        "print(LR.score(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jJtTrqxXfJZ"
      },
      "outputs": [],
      "source": [
        "y_pred= LR.predict(x_test)\n",
        "y_pred= np.exp(y_pred)\n",
        "y_test_lr= np.exp(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OihzhyYXfNz"
      },
      "outputs": [],
      "source": [
        "rmse= np.sqrt(mean_squared_error(y_test_lr, y_pred))\n",
        "mae= mean_absolute_error(y_test_lr, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auilAXfVXfSw"
      },
      "outputs": [],
      "source": [
        "print(\"The RMSE for linear Regression is : \", rmse)\n",
        "print(\"The MAE for Liner Regression is : \", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYluut0dXfWp"
      },
      "outputs": [],
      "source": [
        "model_details(LR, 'LinearRegression')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Random Forest Regression**"
      ],
      "metadata": {
        "id": "3EwZGP4afShL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-RJgzWkXfaF"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "RF= RandomForestRegressor(n_estimators= 600, min_samples_leaf= 100, min_samples_split= 8, max_depth= 8 )\n",
        "RF.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaldJ_PLXfeO"
      },
      "outputs": [],
      "source": [
        "RF.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abMxuML9XfiC"
      },
      "outputs": [],
      "source": [
        "y_pred_rf= RF.predict(x_test)\n",
        "y_pred_rf= np.exp(y_pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xYMLLiCXfl0"
      },
      "outputs": [],
      "source": [
        "rmse=np.sqrt(mean_squared_error(y_test_lr,y_pred_rf))\n",
        "mae= mean_absolute_error(y_test_lr, y_pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF-4zZfjXfpg"
      },
      "outputs": [],
      "source": [
        "print(\"The RMSE for Random Forest is : \", rmse)\n",
        "print(\"The MAE for Random Forest is : \", mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ATrLPp_xGGT"
      },
      "outputs": [],
      "source": [
        "model_details(RF, \"RandomForestRegressor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **XG Boost**"
      ],
      "metadata": {
        "id": "MdbbY7iTkkhG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVn9xFvBxGJT"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "XG= XGBRegressor(learning_rate= 0.05, subsample= 1, max_depth= 2, n_estimator= 400)"
      ],
      "metadata": {
        "id": "nh_I68VtlzkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XG.fit(x_train, y_train)\n",
        "XG.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "w5BLd2j4lz0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xg= XG.predict(x_test)\n",
        "y_pred_xg= np.exp(y_pred_xg)"
      ],
      "metadata": {
        "id": "UXn-5oE-lz4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse= np.sqrt(mean_squared_error(y_test_lr, y_pred_xg))\n",
        "mae= mean_absolute_error(y_test_lr, y_pred_xg)"
      ],
      "metadata": {
        "id": "Y_K3vEO6lz8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The RMSE for XGB Regressor is : \", rmse)\n",
        "print(\"The MAE for XGB Regressor is : \", mae)"
      ],
      "metadata": {
        "id": "EOgr9UDul0AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_details(XG, \"XGBRegressor\")"
      ],
      "metadata": {
        "id": "PvXm5sZ5l0EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comapring Actual sales vs Predicted Sales**\n",
        "As XGB has given the best performance, so i will check with XGB regressor."
      ],
      "metadata": {
        "id": "1-b-sosmqVte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_random= XG.predict(x_test)"
      ],
      "metadata": {
        "id": "wjKaV7C3l0Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_xgb= pd.DataFrame(y_preds_random, columns= ['predicted_xgb'])\n",
        "true_values= list(y_test.values)\n",
        "pred_xgb['true_value']= true_values"
      ],
      "metadata": {
        "id": "HnD2Lpicl0Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_xgb"
      ],
      "metadata": {
        "id": "6X3iZYi7l0Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= np.exp(pred_xgb)\n",
        "a.describe()"
      ],
      "metadata": {
        "id": "vl48CLWRl0Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comp= pred_xgb\n",
        "comp= comp.iloc[1000:1050]\n",
        "true_value= comp['true_value']\n",
        "predicted_values= comp['predicted_xgb']"
      ],
      "metadata": {
        "id": "4cYtKfY8l0Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(true_value)\n",
        "plt.plot(predicted_values)\n",
        "plt.ylabel('Item Outlet Sale')\n",
        "plt.legend(['Actual', \"Predicted\"])\n",
        "plt.title('Item Outlet Sales----> Actual vs Predicted', fontsize= 16)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "eYOhrprrl0dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observation**\n",
        "The RMSE and R squared value is comparatively better for XGB regressor and their R2 score is 72% so we will consider this models according to business requirement , Later on we can try to hyper tune the models and check for the optimum results."
      ],
      "metadata": {
        "id": "qUFpbStFw6W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "3RsDngWnl12f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/prateekkosta/Big-Mart-sales-analysis-/blob/main/BigMart_Data_Analysis.ipynb",
      "authorship_tag": "ABX9TyM4oIlNcCDJeZPHpiUyNPpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}